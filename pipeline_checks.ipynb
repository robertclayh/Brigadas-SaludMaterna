{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2,457 rows × 17 columns from out/adm2_risk_daily.csv\n",
      "\n",
      "Columns: ['run_date', 'adm1_name', 'adm2_name', 'adm2_code', 'pop_wra', 'w_exposure', 'v30', 'v3m', 'dlt_v30_raw', 'spillover', 'cast_state', 'access_A', 'strain_H', 'mvi', 'DCR100', 'PRS100', 'priority100']\n",
      "\n",
      "Missing values per column:\n",
      "run_date       0\n",
      "spillover      0\n",
      "PRS100         0\n",
      "DCR100         0\n",
      "mvi            0\n",
      "strain_H       0\n",
      "access_A       0\n",
      "cast_state     0\n",
      "dlt_v30_raw    0\n",
      "adm1_name      0\n",
      "v3m            0\n",
      "v30            0\n",
      "w_exposure     0\n",
      "pop_wra        0\n",
      "adm2_code      0\n",
      "adm2_name      0\n",
      "priority100    0\n",
      "dtype: int64\n",
      "\n",
      "⚠️ Columns that are entirely zero: []\n",
      "⚠️ Columns with constant values: []\n",
      "\n",
      "Non-zero rate by column:\n",
      "pop_wra        0.999\n",
      "w_exposure     1.000\n",
      "v30            0.058\n",
      "v3m            0.185\n",
      "dlt_v30_raw    0.041\n",
      "spillover      0.280\n",
      "cast_state     0.924\n",
      "access_A       0.868\n",
      "strain_H       0.950\n",
      "mvi            0.950\n",
      "DCR100         0.910\n",
      "PRS100         0.913\n",
      "priority100    0.913\n",
      "dtype: float64\n",
      "\n",
      "DCR100 range: 0.000 to 164.166, mean=32.379, nonzero%=91.0\n",
      "\n",
      "PRS100 range: 0.000 to 144.633, mean=20.851, nonzero%=91.3\n",
      "\n",
      "priority100 range: 0.000 to 152.446, mean=25.462, nonzero%=91.3\n",
      "\n",
      "access_A range: 0.000 to 1.000, mean=0.326, nonzero%=86.8\n",
      "\n",
      "strain_H range: 0.000 to 1.000, mean=0.363, nonzero%=95.0\n",
      "\n",
      "mvi range: 0.000 to 1.000, mean=0.538, nonzero%=95.0\n",
      "\n",
      "cast_state range: 0.000 to 1.000, mean=0.306, nonzero%=92.4\n",
      "\n",
      "Checking for ADM1 with all-zero values in key metrics...\n",
      "✓ All ADM1 regions have non-zero values for at least one row in each key metric.\n",
      "\n",
      "Top correlations among key metrics:\n",
      "             DCR100  PRS100  priority100  access_A  strain_H   mvi  cast_state\n",
      "DCR100         1.00    0.81         0.94      0.67      0.61 -0.09        0.24\n",
      "PRS100         0.81    1.00         0.96      0.50      0.44 -0.22        0.48\n",
      "priority100    0.94    0.96         1.00      0.61      0.55 -0.17        0.39\n",
      "access_A       0.67    0.50         0.61      1.00      0.94 -0.08        0.14\n",
      "strain_H       0.61    0.44         0.55      0.94      1.00 -0.03        0.11\n",
      "mvi           -0.09   -0.22        -0.17     -0.08     -0.03  1.00       -0.14\n",
      "cast_state     0.24    0.48         0.39      0.14      0.11 -0.14        1.00\n",
      "\n",
      "Validation complete.\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Sanity / validation checks for adm2_risk_daily.csv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "OUT_DIR = Path(\"out\")\n",
    "CSV_PATH = OUT_DIR / \"adm2_risk_daily.csv\"\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(f\"Loaded {len(df):,} rows × {df.shape[1]} columns from {CSV_PATH}\\n\")\n",
    "\n",
    "# --- Basic structure and completeness ---\n",
    "print(\"Columns:\", list(df.columns))\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isna().sum().sort_values(ascending=False))\n",
    "\n",
    "# --- Numeric coverage and all-zero detection ---\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns\n",
    "zero_cols = [c for c in num_cols if (df[c].fillna(0) == 0).all()]\n",
    "const_cols = [c for c in num_cols if df[c].nunique(dropna=True) <= 1]\n",
    "\n",
    "print(\"\\n⚠️ Columns that are entirely zero:\", zero_cols)\n",
    "print(\"⚠️ Columns with constant values:\", const_cols)\n",
    "\n",
    "# --- Non-zero rate (fraction of rows with any value > 0) ---\n",
    "nz_rate = (df[num_cols] > 0).sum() / len(df)\n",
    "print(\"\\nNon-zero rate by column:\")\n",
    "print(nz_rate.round(3))\n",
    "\n",
    "# --- Basic numeric ranges for main indices ---\n",
    "key_cols = [\"DCR100\", \"PRS100\", \"priority100\", \"access_A\", \"strain_H\", \"mvi\", \"cast_state\"]\n",
    "for c in key_cols:\n",
    "    if c in df.columns:\n",
    "        print(f\"\\n{c} range: {df[c].min():.3f} to {df[c].max():.3f}, \"\n",
    "              f\"mean={df[c].mean():.3f}, nonzero%={(df[c] > 0).mean() * 100:.1f}\")\n",
    "\n",
    "# --- ADM1-level zero checks (e.g., ensure no entire state is zero) ---\n",
    "group_keys = [\"adm1_name\"]\n",
    "check_cols = [\"facilities\", \"pop_wra\", \"DCR100\", \"PRS100\", \"priority100\", \"access_A\", \"strain_H\", \"mvi\"]\n",
    "\n",
    "print(\"\\nChecking for ADM1 with all-zero values in key metrics...\")\n",
    "if not all(col in df.columns for col in group_keys):\n",
    "    print(\"[Skip] ADM1 check — missing adm1_name column.\")\n",
    "else:\n",
    "    zero_report = []\n",
    "    for adm1, g in df.groupby(\"adm1_name\"):\n",
    "        for c in [col for col in check_cols if col in g.columns]:\n",
    "            if (g[c].fillna(0) == 0).all():\n",
    "                zero_report.append((adm1, c))\n",
    "    if zero_report:\n",
    "        print(\"⚠️ ADM1-level all-zero metrics detected:\")\n",
    "        for adm1, c in zero_report:\n",
    "            print(f\"  - {adm1}: all zeros in {c}\")\n",
    "    else:\n",
    "        print(\"✓ All ADM1 regions have non-zero values for at least one row in each key metric.\")\n",
    "\n",
    "# --- Sanity thresholds / warnings ---\n",
    "if len(zero_cols) > 0:\n",
    "    print(\"\\n[Warning] Some numeric columns are all zeros; check upstream calculations.\")\n",
    "if len(df) == 0:\n",
    "    print(\"\\n[Warning] Empty CSV — pipeline may have filtered everything out.\")\n",
    "if \"priority100\" in df.columns and df[\"priority100\"].max() <= 0:\n",
    "    print(\"\\n[Warning] priority100 has no positive values (possible normalization issue).\")\n",
    "\n",
    "# --- Optional: quick correlation sanity check (should have some variability) ---\n",
    "if len(df) > 5:\n",
    "    corr = df[num_cols].corr()\n",
    "    print(\"\\nTop correlations among key metrics:\")\n",
    "    print(corr.loc[[c for c in key_cols if c in corr.index], [c for c in key_cols if c in corr.columns]].round(2))\n",
    "\n",
    "print(\"\\nValidation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ADM2 shapefile…\n",
      "ADM2 polygons: 2,457 rows, EPSG:4326\n",
      "\n",
      "Checking CAST (state-level)…\n",
      "CAST coverage: matched 98.6% of ADM2 rows (by state).\n",
      "States with missing CAST matches:\n",
      "           adm1_name adm1_code\n",
      "    Distrito Federal      MX09\n",
      "Querétaro de Arteaga      MX22\n",
      "\n",
      "Checking CONEVAL municipal poverty (ADM2)…\n",
      "CONEVAL coverage: 2,457 / 2,457 ADM2 codes matched (0 missing, 12 extra).\n",
      "poverty_rate describe():\n",
      "count    2466.000000\n",
      "mean       62.002065\n",
      "std        21.903723\n",
      "min         5.450951\n",
      "25%        45.580691\n",
      "50%        62.745101\n",
      "75%        80.316135\n",
      "max        99.646676\n",
      "Name: poverty_rate, dtype: float64\n",
      "\n",
      "Checking CLUES facility counts (ADM2)…\n",
      "CLUES coverage: 932 / 2,457 ADM2 codes matched (1525 missing, 6 extra).\n",
      "facilities describe():\n",
      "count    938.000000\n",
      "mean       6.152452\n",
      "std       12.040008\n",
      "min        1.000000\n",
      "25%        1.000000\n",
      "50%        2.000000\n",
      "75%        6.000000\n",
      "max      135.000000\n",
      "Name: facilities, dtype: float64\n",
      "\n",
      "Checking Population (ADM2)…\n",
      "Population coverage: 2,457 / 2,457 ADM2 codes matched (0 missing, 0 extra).\n",
      "pop_total describe():\n",
      "count    2.457000e+03\n",
      "mean     5.365294e+04\n",
      "std      1.538357e+05\n",
      "min      0.000000e+00\n",
      "25%      4.681000e+03\n",
      "50%      1.426500e+04\n",
      "75%      3.788100e+04\n",
      "max      2.010930e+06\n",
      "Name: pop_total, dtype: float64\n",
      "pop_wra describe():\n",
      "count      2457.000000\n",
      "mean      13413.235653\n",
      "std       38458.936944\n",
      "min           0.000000\n",
      "25%        1170.000000\n",
      "50%        3566.000000\n",
      "75%        9470.000000\n",
      "max      502732.000000\n",
      "Name: pop_wra, dtype: float64\n",
      "\n",
      "ACLED events verification (optional)…\n",
      "No ACLED events CSV at data/acled_events_90d.csv; skipping ACLED spatial/name join checks.\n",
      "\n",
      "Checks complete. Reports (if any) are in out/checks/\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# Input Join Checker — ADM2/ADM1 consistency and ACLED spatial/name joins\n",
    "\n",
    "# %%\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from unidecode import unidecode\n",
    "\n",
    "# Optional: spatial join test for ACLED event points if present\n",
    "ACLED_POINTS_CSV = Path(\"data/acled_events_90d.csv\")  # optional; needs latitude, longitude\n",
    "\n",
    "DATA_DIR = Path(\"data\")\n",
    "OUT_DIR  = Path(\"out/checks\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Core inputs (as produced/used in your pipeline)\n",
    "ADM2_SHP         = DATA_DIR / \"mex_admbnda_govmex_20210618_SHP\" / \"mex_admbnda_adm2_govmex_20210618.shp\"\n",
    "POP_CSV          = DATA_DIR / \"pop_adm2.csv\"                       # adm2_code, pop_total, pop_wra\n",
    "CLUES_CSV        = DATA_DIR / \"clues_facility_counts_adm2.csv\"     # adm2_code, facilities\n",
    "CONEVAL_CSV      = DATA_DIR / \"coneval_muni.csv\"                    # adm2_code, poverty_rate\n",
    "CAST_STATE_CSV   = DATA_DIR / \"cast_state.csv\"                      # adm1_name, cast_raw (or scaled)\n",
    "\n",
    "# Utility: consistent name normalization (strip accents, case, extra spaces)\n",
    "def norm_name(s: pd.Series) -> pd.Series:\n",
    "    return (\n",
    "        s.fillna(\"\")\n",
    "         .astype(str)\n",
    "         .str.strip()\n",
    "         .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "         .apply(lambda x: unidecode(x).strip().title())\n",
    "    )\n",
    "\n",
    "def as_str_no_nan(x):\n",
    "    return x.fillna(\"\").astype(str)\n",
    "\n",
    "print(\"Loading ADM2 shapefile…\")\n",
    "adm2 = gpd.read_file(ADM2_SHP)\n",
    "# Keep only what we need\n",
    "keep_cols = [\"ADM1_ES\",\"ADM1_PCODE\",\"ADM2_ES\",\"ADM2_PCODE\",\"geometry\"]\n",
    "adm2 = adm2[keep_cols].rename(columns={\n",
    "    \"ADM1_ES\": \"adm1_name\",\n",
    "    \"ADM1_PCODE\": \"adm1_code\",\n",
    "    \"ADM2_ES\": \"adm2_name\",\n",
    "    \"ADM2_PCODE\":\"adm2_code\"\n",
    "}).to_crs(4326)\n",
    "\n",
    "# Normalize readable names (codes remain as-is)\n",
    "adm2[\"adm1_name_norm\"] = norm_name(adm2[\"adm1_name\"])\n",
    "adm2[\"adm2_name_norm\"] = norm_name(adm2[\"adm2_name\"])\n",
    "adm2[\"adm2_code\"]      = as_str_no_nan(adm2[\"adm2_code\"])\n",
    "\n",
    "print(f\"ADM2 polygons: {len(adm2):,} rows, {adm2.crs}\")\n",
    "\n",
    "# --- CAST (ADM1) check ---\n",
    "print(\"\\nChecking CAST (state-level)…\")\n",
    "if CAST_STATE_CSV.exists():\n",
    "    cast = pd.read_csv(CAST_STATE_CSV)\n",
    "    # Support either cast_raw or pre-scaled column\n",
    "    if \"cast_raw\" in cast.columns:\n",
    "        cast[\"cast_state\"] = cast[\"cast_raw\"]\n",
    "    elif \"cast_state\" not in cast.columns:\n",
    "        cast[\"cast_state\"] = np.nan\n",
    "    cast[\"adm1_name_norm\"] = norm_name(cast[\"adm1_name\"])\n",
    "    # Distinct to avoid dupes\n",
    "    cast1 = cast[[\"adm1_name_norm\",\"cast_state\"]].drop_duplicates()\n",
    "\n",
    "    # Left-join CAST to ADM2 by normalized ADM1 name\n",
    "    adm2_cast = adm2.merge(cast1, on=\"adm1_name_norm\", how=\"left\")\n",
    "\n",
    "    # Report coverage\n",
    "    missing_cast = adm2_cast[adm2_cast[\"cast_state\"].isna()][[\"adm1_name\",\"adm1_code\"]].drop_duplicates()\n",
    "    print(f\"CAST coverage: matched {adm2_cast['cast_state'].notna().mean():.1%} of ADM2 rows (by state).\")\n",
    "    if not missing_cast.empty:\n",
    "        print(\"States with missing CAST matches:\")\n",
    "        print(missing_cast.to_string(index=False))\n",
    "        missing_cast.to_csv(OUT_DIR / \"cast_missing_states.csv\", index=False)\n",
    "else:\n",
    "    print(\"CAST file not found; skipping CAST checks.\")\n",
    "\n",
    "# --- CONEVAL (ADM2) check ---\n",
    "print(\"\\nChecking CONEVAL municipal poverty (ADM2)…\")\n",
    "if CONEVAL_CSV.exists():\n",
    "    coneval = pd.read_csv(CONEVAL_CSV, dtype={\"adm2_code\":\"string\"})\n",
    "    coneval[\"adm2_code\"] = as_str_no_nan(coneval[\"adm2_code\"])\n",
    "    # coverage\n",
    "    adm2_codes = set(adm2[\"adm2_code\"])\n",
    "    cv_codes   = set(coneval[\"adm2_code\"])\n",
    "    missing_in_coneval = sorted(adm2_codes - cv_codes)\n",
    "    extra_in_coneval   = sorted(cv_codes - adm2_codes)\n",
    "\n",
    "    print(f\"CONEVAL coverage: {len(cv_codes & adm2_codes):,} / {len(adm2_codes):,} ADM2 codes matched ({len(missing_in_coneval)} missing, {len(extra_in_coneval)} extra).\")\n",
    "    pd.DataFrame({\"adm2_code\": missing_in_coneval}).to_csv(OUT_DIR/\"coneval_missing_adm2.csv\", index=False)\n",
    "    pd.DataFrame({\"adm2_code\": extra_in_coneval}).to_csv(OUT_DIR/\"coneval_extra_adm2.csv\", index=False)\n",
    "\n",
    "    # Quick distribution of poverty_rate\n",
    "    if \"poverty_rate\" in coneval.columns:\n",
    "        desc = coneval[\"poverty_rate\"].describe()\n",
    "        print(\"poverty_rate describe():\")\n",
    "        print(desc)\n",
    "else:\n",
    "    print(\"CONEVAL file not found; skipping CONEVAL checks.\")\n",
    "\n",
    "# --- CLUES (ADM2) check ---\n",
    "print(\"\\nChecking CLUES facility counts (ADM2)…\")\n",
    "if CLUES_CSV.exists():\n",
    "    clues = pd.read_csv(CLUES_CSV, dtype={\"adm2_code\":\"string\"})\n",
    "    clues[\"adm2_code\"] = as_str_no_nan(clues[\"adm2_code\"])\n",
    "\n",
    "    cl_codes = set(clues[\"adm2_code\"])\n",
    "    missing_in_clues = sorted(adm2_codes - cl_codes)\n",
    "    extra_in_clues   = sorted(cl_codes - adm2_codes)\n",
    "\n",
    "    print(f\"CLUES coverage: {len(cl_codes & adm2_codes):,} / {len(adm2_codes):,} ADM2 codes matched ({len(missing_in_clues)} missing, {len(extra_in_clues)} extra).\")\n",
    "    pd.DataFrame({\"adm2_code\": missing_in_clues}).to_csv(OUT_DIR/\"clues_missing_adm2.csv\", index=False)\n",
    "    pd.DataFrame({\"adm2_code\": extra_in_clues}).to_csv(OUT_DIR/\"clues_extra_adm2.csv\", index=False)\n",
    "\n",
    "    # sanity on counts\n",
    "    if \"facilities\" in clues.columns:\n",
    "        print(\"facilities describe():\")\n",
    "        print(clues[\"facilities\"].describe())\n",
    "else:\n",
    "    print(\"CLUES file not found; skipping CLUES checks.\")\n",
    "\n",
    "# --- POP (ADM2) check ---\n",
    "print(\"\\nChecking Population (ADM2)…\")\n",
    "if POP_CSV.exists():\n",
    "    pop = pd.read_csv(POP_CSV, dtype={\"adm2_code\":\"string\"})\n",
    "    pop[\"adm2_code\"] = as_str_no_nan(pop[\"adm2_code\"])\n",
    "    pp_codes = set(pop[\"adm2_code\"])\n",
    "    missing_in_pop = sorted(adm2_codes - pp_codes)\n",
    "    extra_in_pop   = sorted(pp_codes - adm2_codes)\n",
    "\n",
    "    print(f\"Population coverage: {len(pp_codes & adm2_codes):,} / {len(adm2_codes):,} ADM2 codes matched ({len(missing_in_pop)} missing, {len(extra_in_pop)} extra).\")\n",
    "    pd.DataFrame({\"adm2_code\": missing_in_pop}).to_csv(OUT_DIR/\"pop_missing_adm2.csv\", index=False)\n",
    "    pd.DataFrame({\"adm2_code\": extra_in_pop}).to_csv(OUT_DIR/\"pop_extra_adm2.csv\", index=False)\n",
    "\n",
    "    for col in [\"pop_total\",\"pop_wra\"]:\n",
    "        if col in pop.columns:\n",
    "            print(f\"{col} describe():\")\n",
    "            print(pop[col].describe())\n",
    "else:\n",
    "    print(\"Population file not found; skipping POP checks.\")\n",
    "\n",
    "# --- Optional: ACLED points name-join vs spatial-join comparison ---\n",
    "print(\"\\nACLED events verification (optional)…\")\n",
    "if ACLED_POINTS_CSV.exists():\n",
    "    # Expect columns: latitude, longitude; optionally admin1/admin2\n",
    "    events = pd.read_csv(ACLED_POINTS_CSV)\n",
    "    # Basic cleaning\n",
    "    latcol = next((c for c in events.columns if c.lower() == \"latitude\"), None)\n",
    "    loncol = next((c for c in events.columns if c.lower() == \"longitude\"), None)\n",
    "    if not latcol or not loncol:\n",
    "        print(\"ACLED points present but missing latitude/longitude columns; skipping spatial join test.\")\n",
    "    else:\n",
    "        # Spatial join\n",
    "        ev_gdf = gpd.GeoDataFrame(\n",
    "            events.dropna(subset=[latcol, loncol]).copy(),\n",
    "            geometry=gpd.points_from_xy(events[loncol], events[latcol]),\n",
    "            crs=4326\n",
    "        )\n",
    "\n",
    "        # Keep small sample if extremely large\n",
    "        if len(ev_gdf) > 250_000:\n",
    "            ev_gdf = ev_gdf.sample(250_000, random_state=42).copy()\n",
    "            print(f\"Sampled 250,000 events for spatial join speed (from {len(events):,}).\")\n",
    "\n",
    "        ev_in_adm2 = gpd.sjoin(ev_gdf, adm2[[\"adm2_code\",\"adm1_name_norm\",\"adm2_name_norm\",\"geometry\"]],\n",
    "                               how=\"left\", predicate=\"within\").drop(columns=[\"index_right\"])\n",
    "\n",
    "        # Name-join attempt (if admin1/admin2 exist)\n",
    "        a1 = next((c for c in events.columns if c.lower() in {\"admin1\",\"adm1\",\"state\"}), None)\n",
    "        a2 = next((c for c in events.columns if c.lower() in {\"admin2\",\"adm2\",\"municipio\",\"municipality\"}), None)\n",
    "\n",
    "        if a1 and a2:\n",
    "            tmp = ev_in_adm2.copy()\n",
    "            tmp[\"admin1_norm\"] = norm_name(tmp[a1])\n",
    "            tmp[\"admin2_norm\"] = norm_name(tmp[a2])\n",
    "\n",
    "            # merge to ADM2 names to get a code by names\n",
    "            name_join = tmp.merge(\n",
    "                adm2[[\"adm2_code\",\"adm1_name_norm\",\"adm2_name_norm\"]],\n",
    "                left_on=[\"admin1_norm\",\"admin2_norm\"],\n",
    "                right_on=[\"adm1_name_norm\",\"adm2_name_norm\"],\n",
    "                how=\"left\",\n",
    "                suffixes=(\"\",\"_adm\")\n",
    "            )\n",
    "\n",
    "            # compare codes: spatial vs name-based\n",
    "            both = name_join[[\"adm2_code\", \"adm2_code_adm\"]].copy()\n",
    "            both[\"match\"] = both[\"adm2_code\"].fillna(\"\") == both[\"adm2_code_adm\"].fillna(\"\")\n",
    "            rate = both[\"match\"].mean()\n",
    "            mism = both[~both[\"match\"]].head(20)\n",
    "            print(f\"Name vs spatial join agreement: {rate:.1%} (sample of {len(both):,} events)\")\n",
    "            if not mism.empty:\n",
    "                mism.to_csv(OUT_DIR/\"acled_name_vs_spatial_mismatches_sample.csv\", index=False)\n",
    "                print(\"Wrote sample mismatches to out/checks/acled_name_vs_spatial_mismatches_sample.csv\")\n",
    "        else:\n",
    "            print(\"ACLED events lack admin1/admin2 columns; only spatial coverage was checked.\")\n",
    "\n",
    "        # Spatial coverage rate\n",
    "        cov = ev_in_adm2[\"adm2_code\"].notna().mean()\n",
    "        print(f\"Spatial join coverage (events within ADM2 polygons): {cov:.1%} of events\")\n",
    "else:\n",
    "    print(\"No ACLED events CSV at data/acled_events_90d.csv; skipping ACLED spatial/name join checks.\")\n",
    "\n",
    "print(\"\\nChecks complete. Reports (if any) are in out/checks/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting Mexico events 2025-09-25 → 2025-10-25\n",
      "No rows returned. Possible causes: recency cap or filters too narrow.\n",
      "Server message: (no message)\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import os\n",
    "import datetime as dt\n",
    "import requests\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# --- Config ---\n",
    "TOKEN_URL = \"https://acleddata.com/oauth/token\"\n",
    "READ_URL  = \"https://acleddata.com/api/acled/read\"  # default JSON\n",
    "COUNTRY   = \"Mexico\"\n",
    "\n",
    "# --- Auth ---\n",
    "load_dotenv()\n",
    "ACLED_USER = os.getenv(\"ACLED_USER\")\n",
    "ACLED_PASS = os.getenv(\"ACLED_PASS\")\n",
    "assert ACLED_USER and ACLED_PASS, \"Set ACLED_USER and ACLED_PASS in your .env\"\n",
    "\n",
    "tok = requests.post(\n",
    "    TOKEN_URL,\n",
    "    headers={\"Content-Type\": \"application/x-www-form-urlencoded\"},\n",
    "    data={\n",
    "        \"username\": ACLED_USER,\n",
    "        \"password\": ACLED_PASS,\n",
    "        \"grant_type\": \"password\",\n",
    "        \"client_id\": \"acled\",\n",
    "    },\n",
    "    timeout=60,\n",
    ")\n",
    "tok.raise_for_status()\n",
    "access_token = tok.json()[\"access_token\"]\n",
    "\n",
    "# --- Date window: last 30 days ---\n",
    "end = dt.date.today()\n",
    "start = end - dt.timedelta(days=30)\n",
    "print(f\"Requesting {COUNTRY} events {start} → {end}\")\n",
    "\n",
    "# --- Fetch JSON (default) ---\n",
    "params = {\n",
    "    \"country\": COUNTRY,\n",
    "    \"event_date\": f\"{start}|{end}\",\n",
    "    \"event_date_where\": \"BETWEEN\",\n",
    "    \"limit\": 5000,  # pagination not needed for a 30-day window typically\n",
    "}\n",
    "r = requests.get(\n",
    "    READ_URL,\n",
    "    headers={\"Authorization\": f\"Bearer {access_token}\"},\n",
    "    params=params,\n",
    "    timeout=120,\n",
    ")\n",
    "r.raise_for_status()\n",
    "\n",
    "js = r.json()\n",
    "# ACLED responses include a \"status\" field; 200 means OK even if 'data' is empty.\n",
    "status = js.get(\"status\")\n",
    "data = js.get(\"data\", [])\n",
    "\n",
    "if status != 200:\n",
    "    print(f\"ACLED returned status {status}. Full response:\\n{js}\")\n",
    "elif not data:\n",
    "    # Helpful diagnostics when empty\n",
    "    msg = js.get(\"message\") or js.get(\"detail\") or \"(no message)\"\n",
    "    print(\"No rows returned. Possible causes: recency cap or filters too narrow.\")\n",
    "    print(f\"Server message: {msg}\")\n",
    "else:\n",
    "    df = pd.DataFrame(data)\n",
    "    print(f\"Downloaded {len(df):,} rows; columns: {list(df.columns)[:10]}…\")\n",
    "    out = \"acled_mexico_30d.csv\"\n",
    "    df.to_csv(out, index=False)\n",
    "    print(f\"Saved → {out}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brigadas-SaludMaterna — Data Pipeline (README)\n",
    "\n",
    "## Overview\n",
    "\n",
    "This repository hosts a reproducible Python data pipeline designed to generate ADM2-level risk tables that support maternal health brigades operating in Mexico under humanitarian programming. The pipeline operationalizes an evidence-based risk prioritization model, integrating multiple data sources to provide actionable insights for targeting interventions where they are most needed. By transforming complex datasets into concise, interpretable risk scores, the pipeline empowers program managers and field teams with timely, data-driven decision support.\n",
    "\n",
    "The risk model combines structural vulnerabilities and dynamic indicators to capture both current and near-term maternal health risks. This approach aligns with evidence-based programming, ensuring resources are allocated efficiently to municipalities facing the greatest challenges.\n",
    "\n",
    "### Input Variables and Conceptual Roles\n",
    "\n",
    "- **Violence (ACLED event counts):** Violence adversely affects maternal health by disrupting access to care and increasing stress and insecurity. Including recent violent event counts captures acute risk factors impacting communities.\n",
    "\n",
    "- **Access (CLUES facility density):** Facility density inversely represents healthcare access. Lower density indicates potential barriers to maternal health services, which is critical for identifying underserved areas.\n",
    "\n",
    "- **Poverty (CONEVAL municipal poverty rates):** Socioeconomic deprivation is a key determinant of health outcomes. Poverty rates contextualize structural vulnerabilities influencing maternal health risks.\n",
    "\n",
    "- **Spillover (Neighboring violence rates):** Violence and instability can spread geographically. The spillover metric captures the influence of violence in adjacent municipalities, acknowledging spatial contagion effects.\n",
    "\n",
    "- **CAST Forecast (ACLED state-level forecast):** The CAST forecast provides predictive insight into likely near-term violence trends, enabling anticipatory program adjustments.\n",
    "\n",
    "### Weighting Logic\n",
    "\n",
    "The risk scores are constructed by weighting these inputs to reflect their relative importance based on prior validation and expert consensus. Structural factors like violence trends and access receive higher weights due to their direct impact on maternal health outcomes, while spillover and poverty contribute complementary context. The weighting scheme balances stability (structural risk) and responsiveness (predictive risk) to generate actionable priority scores.\n",
    "\n",
    "### Where to find the tables\n",
    "\n",
    "- **Google Sheet:** `[Insert Google Sheet URL here]` (tabs: `adm2_risk_daily`, `acled_events_90d`, `adm2_geometry`, `sources_log`)  \n",
    "- **CSVs in repo:**  \n",
    "  - `out/adm2_risk_daily.csv` `[Insert CSV URL here]`  \n",
    "  - `out/acled_events_violent_90d.csv` `[Insert CSV URL here]`  \n",
    "  - `out/adm2_geometry.csv` `[Insert CSV URL here]`\n",
    "\n",
    "---\n",
    "\n",
    "## What the Pipeline Produces (Viz-Ready Tables)\n",
    "\n",
    "### 1) `adm2_risk_daily.csv` — main fact table (one row per ADM2)\n",
    "\n",
    "| Column        | Meaning                                                                                           |\n",
    "|:--------------|:-------------------------------------------------------------------------------------------------|\n",
    "| `run_date`    | Date the pipeline ran.                                                                            |\n",
    "| `data_as_of`  | Last ACLED date available (recency cap).                                                        |\n",
    "| `adm1_name`, `adm2_name`, `adm2_code` | State, municipality, INEGI/COD-AB code (e.g., MX25008).                                    |\n",
    "| `pop_total`, `pop_wra` | Total population & women 15–49 (WRA, proxied @25%).                                          |\n",
    "| `v30`, `v3m`  | Events per 100k WRA in last 30/90 days (violent types).                                          |\n",
    "| `dlt_v30_raw` | v30 minus previous 30-day rate.                                                                  |\n",
    "| `spillover`   | Queen-contiguity neighbor average of v30.                                                       |\n",
    "| `cast_state`  | State-level CAST forecast (0–1, winsorized 5–95%).                                              |\n",
    "| `access_A`    | Inverse facility density (facilities per 100k WRA), scaled 0–1.                                 |\n",
    "| `mvi`         | Municipal poverty (CONEVAL 2020 % pobreza), scaled 0–1.                                         |\n",
    "| `DCR100`      | 100 × [0.35·V3m + 0.15·S + 0.30·A + 0.20·MVI].                                                 |\n",
    "| `PRS100`      | 100 × [with CAST: 0.30·V30 + 0.25·dV30 + 0.10·S + 0.18·CAST + 0.12·A + 0.05·MVI; without CAST: 0.40·V30 + 0.30·dV30 + 0.10·S + 0.12·A + 0.08·MVI]. |\n",
    "| `priority100` | 100 × [0.6·PRS + 0.4·DCR].                                                                      |\n",
    "\n",
    "**Notes:** V30/V3m/dV30/S/CAST/A/MVI are all winsorized & scaled so higher = worse.  \n",
    "Removed `strain_H` to avoid double-counting with `access_A` (high correlation).\n",
    "\n",
    "### Mathematical Formulations\n",
    "\n",
    "The **Descriptive Composite Risk (DCR100)** is calculated as:\n",
    "\n",
    "$$\n",
    "\\text{DCR100} = 100 \\times \\left( 0.35 \\times V_{3m} + 0.15 \\times S + 0.30 \\times A + 0.20 \\times MVI \\right)\n",
    "$$\n",
    "\n",
    "where:  \n",
    "- \\( V_{3m} \\) = 90-day violent event rate per 100k WRA  \n",
    "- \\( S \\) = Spillover (neighbor average violence rate)  \n",
    "- \\( A \\) = Inverse facility density (access)  \n",
    "- \\( MVI \\) = Municipal poverty index\n",
    "\n",
    "The **Predictive Risk Score (PRS100)** incorporates recent trends and forecasts:\n",
    "\n",
    "$$\n",
    "\\text{PRS100} = 100 \\times \\left( 0.30 \\times V_{30} + 0.25 \\times \\Delta V_{30} + 0.10 \\times S + 0.18 \\times CAST + 0.12 \\times A + 0.05 \\times MVI \\right)\n",
    "$$\n",
    "\n",
    "(with CAST forecast available), or:\n",
    "\n",
    "$$\n",
    "\\text{PRS100} = 100 \\times \\left( 0.40 \\times V_{30} + 0.30 \\times \\Delta V_{30} + 0.10 \\times S + 0.12 \\times A + 0.08 \\times MVI \\right)\n",
    "$$\n",
    "\n",
    "(without CAST forecast), where:  \n",
    "- \\( V_{30} \\) = 30-day violent event rate per 100k WRA  \n",
    "- \\( \\Delta V_{30} \\) = Change in 30-day violent event rate  \n",
    "- \\( CAST \\) = State-level forecast of violence risk\n",
    "\n",
    "The final **priority score** balances predictive and descriptive risk:\n",
    "\n",
    "$$\n",
    "\\text{priority100} = 100 \\times (0.6 \\times PRS + 0.4 \\times DCR)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### 2) `acled_events_90d.csv` — event points for map layers\n",
    "\n",
    "ACLED violent events (last 90 days), with original ACLED fields (`event_id_cnty`, `event_date`, `event_type`, `latitude`, `longitude`, `source`, etc.) plus the joined `adm2_code`/`adm2_name`, and `run_date`/`data_as_of`. Ready for direct plotting.\n",
    "\n",
    "---\n",
    "\n",
    "### 3) `adm2_geometry.csv` — centroids helper\n",
    "\n",
    "Minimal lookup (`adm1_name`, `adm2_name`, `adm2_code`, `lon`, `lat`) for lightweight map layers or tooltips.\n",
    "\n",
    "---\n",
    "\n",
    "## How It Refreshes (Automation & Caching)\n",
    "\n",
    "- **Daily API refresh:**\n",
    "  - ACLED events (last 90 days and prior 30 days)\n",
    "  - ACLED CAST (state-level forecasts, scaled)\n",
    "- **Caching:** Stores meta file (`out/acled_meta.json`) and last pulled CSVs.  \n",
    "  If the ACLED recency cap hasn’t advanced, the API call is skipped.\n",
    "- **Static builds:** Population (WorldPop raster), CLUES facilities, CONEVAL poverty (one-time unless missing).\n",
    "\n",
    "**Important:** ACLED’s public “recency” restriction means recent events may be unavailable.  \n",
    "The pipeline records `data_as_of` to reflect this and uses cached data if the cap is unchanged.\n",
    "\n",
    "---\n",
    "\n",
    "## Data Access Caveat (ACLED Licensing Changes)\n",
    "\n",
    "ACLED has recently modified its data access policy, instituting a 12-month embargo on disaggregated event-level data. This change means that detailed, municipality-level event data from the most recent year are no longer publicly accessible immediately upon release.\n",
    "\n",
    "The current ETL design, indicator weighting, and modeling framework assume access to recent disaggregated ACLED data to capture acute and near-term violence trends critical for accurate risk prioritization at the ADM2 level.\n",
    "\n",
    "In response to this policy update, a contingency plan has been developed. Should access to recent disaggregated data remain restricted, the pipeline and model will be recalibrated to rely more heavily on longer-term violence trends and aggregated indicators, such as state-level forecasts and structural risk factors. This approach aims to preserve the model’s predictive integrity and utility for programmatic decision-making while complying with ACLED’s licensing constraints.\n",
    "\n",
    "---\n",
    "\n",
    "## Running the Pipeline\n",
    "\n",
    "### Environment\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "or ensure the following are installed:\n",
    "\n",
    "```bash\n",
    "pandas geopandas shapely pyproj rtree libpysal rasterio rasterstats\n",
    "requests python-dotenv gspread gspread-dataframe oauth2client unidecode\n",
    "```\n",
    "\n",
    "### Secrets\n",
    "\n",
    "Create a `.env` file in the repo root:\n",
    "\n",
    "```env\n",
    "ACLED_USER=your_email@domain\n",
    "ACLED_PASS=your_password\n",
    "ACLED_REFRESH=true\n",
    "CAST_REFRESH=true\n",
    "SSL_VERIFY=true\n",
    "# Optional:\n",
    "# FORCE_REBUILD_POP=false\n",
    "```\n",
    "\n",
    "Add your Google service account JSON to the repo root and set in `pipeline.py`:\n",
    "\n",
    "```python\n",
    "GOOGLE_CREDS_JSON = ROOT / \"brigadas-salud-materna-<id>.json\"\n",
    "```\n",
    "\n",
    "Share the Google Sheet or folder with the service account email.\n",
    "\n",
    "### Execute\n",
    "\n",
    "```bash\n",
    "python pipeline.py\n",
    "```\n",
    "\n",
    "Outputs:\n",
    "- `out/adm2_risk_daily.csv`\n",
    "- `out/acled_events_violent_90d.csv`\n",
    "- `out/adm2_geometry.csv`\n",
    "\n",
    "Uploaded to Google Sheets tabs (in order):  \n",
    "`adm2_risk_daily`, `acled_events_90d`, `adm2_geometry`, `sources_log`.\n",
    "\n",
    "---\n",
    "\n",
    "## Data Sources & Transformations (Citations)\n",
    "\n",
    "- ACLED: Armed Conflict Location & Event Data Project — events & CAST forecasts via API.  \n",
    "  Filters: Mexico, violent event types, rolling 90d & 30d windows.  \n",
    "  Attribution: © ACLED, access logged in `data_as_of`.\n",
    "- WorldPop (R2025A): 2025 population, 100m WGS84. Aggregated via rasterstats.  \n",
    "  WRA estimated as 25% of total. DOI: 10.5258/SOTON/WP00839\n",
    "- CLUES (DGIS/Secretaría de Salud): ESTABLECIMIENTO_SALUD_202509.xlsx  \n",
    "  Filters: public networks, active, non-mobile, valid coordinates. Spatial join to ADM2 polygons.\n",
    "- CONEVAL 2020: Municipal poverty (% pobreza).  \n",
    "  Extracted by municipal code, mapped to ADM2 via MX+state+municipio key.\n",
    "- Boundaries: COD-AB Mexico ADM2 from HDX, used for joins, spillover, and centroids.\n",
    "\n",
    "### Key Transforms\n",
    "\n",
    "- Winsorize indicators (5–95%), scale to 0–1 (higher = worse).\n",
    "- Spillover = neighbor average of v30 via libpysal.Queen.\n",
    "- DCR100 = 100 × [0.35·V3m + 0.15·S + 0.30·A + 0.20·MVI]\n",
    "- PRS100 = 100 × [with CAST: 0.30·V30 + 0.25·dV30 + 0.10·S + 0.18·CAST + 0.12·A + 0.05·MVI]\n",
    "- priority100 = 100 × [0.6·PRS + 0.4·DCR]\n",
    "\n",
    "---\n",
    "\n",
    "## Quick Links\n",
    "\n",
    "- `adm2_risk_daily.csv` `[Insert CSV URL here]`\n",
    "- `acled_events_violent_90d.csv` `[Insert CSV URL here]`\n",
    "- `adm2_geometry.csv` `[Insert CSV URL here]`\n",
    "- Google Sheet: `mx_brigadas_dashboard` `[Insert Google Sheet URL here]` (tabs auto-created by pipeline)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
